{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm, trange\n",
    "import time\n",
    "import torch \n",
    "from torch.optim import Adam \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\").fillna(method='ffill')\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
       "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
       "       'I-eve', 'I-nat'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data \n",
    "        self.empty = False \n",
    "        agg_func = lambda s: [(w,p,t) for w,p,t in zip(s['Word'].values.tolist(),\n",
    "                                                      s['POS'].values.tolist(),\n",
    "                                                      s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "        \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1 \n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [' '.join([y[0] for y in x]) for x in getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[y[2] for y in x] for x in getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-geo',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-geo',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-gpe',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-tim': 0,\n",
       " 'I-nat': 1,\n",
       " 'O': 2,\n",
       " 'I-eve': 3,\n",
       " 'I-per': 4,\n",
       " 'B-geo': 5,\n",
       " 'I-gpe': 6,\n",
       " 'B-nat': 7,\n",
       " 'I-org': 8,\n",
       " 'B-per': 9,\n",
       " 'B-gpe': 10,\n",
       " 'B-eve': 11,\n",
       " 'B-org': 12,\n",
       " 'I-tim': 13,\n",
       " 'B-art': 14,\n",
       " 'I-geo': 15,\n",
       " 'I-art': 16}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_vals = list(set(data['Tag'].values))\n",
    "tag2idx = {t:i for i,t in enumerate(tags_vals)}\n",
    "idx2tag = {i: t for t, i in tag2idx.items()}\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 75\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                         maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5190,  1997, 28337,  2031,  9847,  2083,  2414,  2000,  6186,\n",
       "        1996,  2162,  1999,  5712,  1998,  5157,  1996, 10534,  1997,\n",
       "        2329,  3629,  2013,  2008,  2406,  1012,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                    maxlen=MAX_LEN, value=tag2idx['O'], padding='post',\n",
    "                    dtype='long', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_u, input_ids_v, tags_u, tags_v = train_test_split(input_ids,\n",
    "                                                           tags,\n",
    "                                                           random_state=2018,\n",
    "                                                           test_size=0.015)\n",
    "\n",
    "attention_masks_u, attention_masks_v, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                            random_state=2018, test_size=0.015)\n",
    "\n",
    "\n",
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids_v,\n",
    "                                                           tags_v,\n",
    "                                                           random_state=2018,\n",
    "                                                           test_size=0.4)\n",
    "\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks_v, input_ids_v,\n",
    "                                            random_state=2018, test_size=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = False\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias','gamma','beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate':0.01},\n",
    "        {'params':[p for n,p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate':0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{'params':[p for n,p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(valid_tags, pred_tags):\n",
    "\n",
    "    \"\"\"\n",
    "    Define a flat accuracy metric to use while training the model.\n",
    "    \"\"\"\n",
    "\n",
    "    return (np.array(valid_tags) == np.array(pred_tags)).mean()\n",
    "\n",
    "def annot_confusion_matrix(valid_tags, pred_tags):\n",
    "\n",
    "    \"\"\"\n",
    "    Create an annotated confusion matrix by adding label\n",
    "    annotations and formatting to sklearn's `confusion_matrix`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create header from unique tags\n",
    "    header = sorted(list(set(valid_tags + pred_tags)))\n",
    "\n",
    "    # Calculate the actual confusion matrix\n",
    "    matrix = confusion_matrix(valid_tags, pred_tags, labels=header)\n",
    "\n",
    "    # Final formatting touches for the string output\n",
    "    mat_formatted = [header[i] + \"\\t\" + str(row) for i, row in enumerate(matrix)]\n",
    "    content = \"\\t\" + \" \".join(header) + \"\\n\" + \"\\n\".join(mat_formatted)\n",
    "\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab[\"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting train loop\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "Train loss: 2.834966387067522\n",
      "Train accuracy: 0.03663605828299611\n",
      "starting validation loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  50%|█████     | 1/2 [01:47<01:47, 107.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.7709459728664823\n",
      "Validation Accuracy: 0.05559395054712171\n",
      "Classificatiotn Report:\\m            precision    recall  f1-score   support\n",
      "\n",
      "      geo       0.03      0.03      0.03       235\n",
      "      tim       0.01      0.02      0.01       125\n",
      "      org       0.01      0.07      0.02       120\n",
      "      per       0.00      0.02      0.01       106\n",
      "      gpe       0.02      0.08      0.04        89\n",
      "      eve       0.00      0.00      0.00         2\n",
      "      nat       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.01      0.04      0.01       678\n",
      "macro avg       0.02      0.04      0.02       678\n",
      "\n",
      "Confusion Matrix:\n",
      " \tB-art B-eve B-geo B-gpe B-nat B-org B-per B-tim I-art I-eve I-geo I-gpe I-nat I-org I-per I-tim O\n",
      "B-art\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "B-eve\t[0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
      "B-geo\t[ 2 10  0  9  4  2 13  1 88  2 14  2  4 51  1 21 11]\n",
      "B-gpe\t[ 0  1  0  6  0  0  5  0 49  1  2  2  0 12  0  3  8]\n",
      "B-nat\t[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "B-org\t[ 1  5  1  2  0  1 12  1 48  1  2  2  2 32  0  3  7]\n",
      "B-per\t[ 0  5  0  2  1  1  5  0 43  0  3  2  2 29  0  7  6]\n",
      "B-tim\t[ 1 15  0  2  0  0 11  0 52  2  8  0  4  7  0  7 16]\n",
      "I-art\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "I-eve\t[0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1]\n",
      "I-geo\t[ 0  5  1  1  0  0  5  0  9  0  2  0  1 13  0  2  3]\n",
      "I-gpe\t[0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      "I-nat\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "I-org\t[ 0  1  1  0  0  0  9  0 30  2  6  1  1 32  0  5 11]\n",
      "I-per\t[ 0  9  0  1  0  4  3  0 38  1  4  0  1 31  0  7 15]\n",
      "I-tim\t[ 0  6  0  1  1  0  6  0 19  1  2  0  2  3  0  4  7]\n",
      "O\t[  59  285   20  223   30   45  397   17 2823  114  241   50  110 1031\n",
      "   42  472  358]\n",
      "Checkpoint saved to models/train_checkpoint_epoch_1.tar\n",
      "starting train loop\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "backward pass\n",
      "Train loss: 2.7460029976708547\n",
      "Train accuracy: 0.07984342772762464\n",
      "starting validation loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 100%|██████████| 2/2 [03:37<00:00, 108.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.676004065407647\n",
      "Validation Accuracy: 0.12658010426215843\n",
      "Classificatiotn Report:\\m            precision    recall  f1-score   support\n",
      "\n",
      "      geo       0.02      0.02      0.02       235\n",
      "      tim       0.01      0.02      0.01       125\n",
      "      org       0.01      0.06      0.02       120\n",
      "      per       0.00      0.02      0.01       106\n",
      "      gpe       0.02      0.06      0.03        89\n",
      "      eve       0.00      0.00      0.00         2\n",
      "      nat       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.01      0.03      0.01       678\n",
      "macro avg       0.01      0.03      0.02       678\n",
      "\n",
      "Confusion Matrix:\n",
      " \tB-art B-eve B-geo B-gpe B-nat B-org B-per B-tim I-art I-eve I-geo I-gpe I-nat I-org I-per I-tim O\n",
      "B-art\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "B-eve\t[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "B-geo\t[ 2  9  0  7  4  2 13  1 81  2 12  2  4 47  1 18 30]\n",
      "B-gpe\t[ 0  1  0  4  0  0  5  0 43  0  2  2  0 11  0  2 19]\n",
      "B-nat\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "B-org\t[ 1  5  1  2  0  1 12  1 40  0  2  2  2 28  0  2 21]\n",
      "B-per\t[ 0  4  0  2  0  1  6  0 38  0  3  2  2 28  0  6 14]\n",
      "B-tim\t[ 1 14  0  2  0  0 10  0 51  2  6  0  3  7  0  5 24]\n",
      "I-art\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "I-eve\t[0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1]\n",
      "I-geo\t[ 0  4  1  1  0  0  5  0  8  0  1  0  1 13  0  2  6]\n",
      "I-gpe\t[0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      "I-nat\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "I-org\t[ 0  1  1  0  0  1  8  0 26  1  4  1  1 32  0  4 19]\n",
      "I-per\t[ 0  9  0  1  0  4  3  0 30  1  4  0  0 27  0  7 28]\n",
      "I-tim\t[ 0  5  0  0  1  0  6  0 17  1  2  0  2  2  0  3 13]\n",
      "O\t[  58  259   20  187   23   42  359   17 2611  104  216   46   96  948\n",
      "   40  410  881]\n",
      "Checkpoint saved to models/train_checkpoint_epoch_2.tar\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "max_grad_norm = 1.0\n",
    "pad_tok = tokenizer.vocab[\"[PAD]\"]\n",
    "sep_tok = tokenizer.vocab[\"[SEP]\"]\n",
    "cls_tok = tokenizer.vocab[\"[CLS]\"]\n",
    "o_lab = tag2idx[\"O\"]\n",
    "verbose = True\n",
    "epoch = 0\n",
    "\n",
    "for _ in trange(epochs, desc='Epoch'):\n",
    "    epoch += 1\n",
    "    print('starting train loop')\n",
    "    model.train()\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], [] \n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        #add batch to gpu (cpu probably)\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        #forward pass \n",
    "        outputs = model(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "        )\n",
    "        loss, tr_logits = outputs[:2]\n",
    "        print('backward pass')\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "        #compute train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        #subset out unwanted predictions on CLS/PAD/SEP tokens\n",
    "        preds_mask = (\n",
    "            (b_input_ids != cls_tok) & (b_input_ids != pad_tok) & (b_input_ids != sep_tok)\n",
    "        )\n",
    "        \n",
    "        tr_logits = tr_logits.detach().cpu().numpy()\n",
    "        tr_label_ids = torch.masked_select(b_labels, (preds_mask == 1))\n",
    "        tr_batch_preds = np.argmax(tr_logits[preds_mask.squeeze()], axis=1)\n",
    "        tr_batch_labels = tr_label_ids.to('cpu').numpy()\n",
    "        tr_preds.extend(tr_batch_preds)\n",
    "        tr_labels.extend(tr_batch_labels)\n",
    "        \n",
    "        #compute training accuracy\n",
    "        tmp_tr_accuracy = flat_accuracy(tr_batch_labels, tr_batch_preds)\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "        \n",
    "        #gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=max_grad_norm\n",
    "        )\n",
    "        \n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        \n",
    "    tr_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    \n",
    "    #print training loss and accuracy per epoch \n",
    "    print(f\"Train loss: {tr_loss}\")\n",
    "    print(f\"Train accuracy: {tr_accuracy}\")\n",
    "    \n",
    "    #validation loop \n",
    "    print('starting validation loop')\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "        \n",
    "        #subset out unwanted predictions on cls/pad/sep tokens\n",
    "        preds_mask = (\n",
    "            (b_input_ids != cls_tok) & (b_input_ids != pad_tok) & (b_input_ids != sep_tok)\n",
    "        )\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = torch.masked_select(b_labels, (preds_mask == 1))\n",
    "        val_batch_preds = np.argmax(logits[preds_mask.squeeze()], axis=1)\n",
    "        val_batch_labels = label_ids.to('cpu').numpy()\n",
    "        predictions.extend(val_batch_preds)\n",
    "        true_labels.extend(val_batch_labels)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(val_batch_labels, val_batch_preds)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy \n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "    #evaluate loss, acc, conf matrix and class report on devset \n",
    "    pred_tags = [idx2tag[i] for i in predictions]\n",
    "    valid_tags = [idx2tag[i] for i in true_labels]\n",
    "    cl_report = classification_report(valid_tags, pred_tags)\n",
    "    conf_mat = annot_confusion_matrix(valid_tags, pred_tags)\n",
    "    eval_loss = eval_loss / nb_eval_steps \n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps \n",
    "    \n",
    "    #report metrics \n",
    "    print(f\"Validation loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "    print(f\"Classificatiotn Report:\\m {cl_report}\")\n",
    "    if verbose:\n",
    "        print(f\"Confusion Matrix:\\n {conf_mat}\")\n",
    "        \n",
    "    #save model and optimizer state_dict following every epoch \n",
    "    save_path = f\"models/train_checkpoint_epoch_{epoch}.tar\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\":epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"train_loss\": tr_loss,\n",
    "            \"train_acc\": tr_accuracy,\n",
    "            \"eval_loss\":eval_loss,\n",
    "            \"eval_acc\": eval_accuracy,\n",
    "            \"classification_report\": cl_report,\n",
    "            \"confusion_matrix\": conf_mat,\n",
    "        },\n",
    "        save_path,\n",
    "    )\n",
    "    print(f\"Checkpoint saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the num is d\n"
     ]
    }
   ],
   "source": [
    "print(f\"the num is {'d'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "checkpoint = torch.load('models/train_checkpoint_epoch_2.tar')\n",
    "model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=model_state_dict['classifier.weight'].shape[0]\n",
    ")\n",
    "model.load_state_dict(model_state_dict)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>b_pred_per</th>\n",
       "      <th>b_pred_loc</th>\n",
       "      <th>b_pred_org</th>\n",
       "      <th>b_pred_misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>B-eve</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>I-org</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>I-org</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>I-org</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>I-org</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text   pred  b_pred_per  b_pred_loc  b_pred_org  b_pred_misc\n",
       "0  [CLS]  B-eve           0           0           0            0\n",
       "1  [UNK]      O           0           0           0            0\n",
       "2    was  I-org           0           0           1            0\n",
       "3  right  I-org           0           0           1            0\n",
       "4      .  I-org           0           0           1            0\n",
       "5  [SEP]  I-org           0           0           1            0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Hitler was right.\"\n",
    "encoded_text = tokenizer.encode(input_text)\n",
    "wordpieces = [tokenizer.decode(tok).replace(' ','') for tok in encoded_text]\n",
    "\n",
    "input_ids = torch.tensor(encoded_text).unsqueeze(0).long()\n",
    "labels = torch.tensor([1] * input_ids.size(1)).unsqueeze(0).long()\n",
    "outputs = model(input_ids, labels=labels)\n",
    "loss, scores = outputs[:2]\n",
    "scores = scores.detach().numpy()\n",
    "\n",
    "label_ids = np.argmax(scores, axis=2)\n",
    "preds = [idx2tag[i] for i in label_ids[0]]\n",
    "\n",
    "wp_preds = list(zip(wordpieces, preds))\n",
    "toplevel_preds = [pair[1] for pair in wp_preds if '##' not in pair[0]]\n",
    "str_rep = ' '.join([t[0] for t in wp_preds]).replace(' ##', '').split()\n",
    "\n",
    "if len(str_rep) == len(toplevel_preds):\n",
    "    preds_final = list(zip(str_rep, toplevel_preds))\n",
    "    b_preds_df = pd.DataFrame(preds_final)\n",
    "    b_preds_df.columns = ['text','pred']\n",
    "    for tag in ['PER','LOC','ORG','MISC']:\n",
    "        b_preds_df[f\"b_pred_{tag.lower()}\"] = np.where(\n",
    "            b_preds_df['pred'].str.contains(tag.lower()), 1, 0\n",
    "        )\n",
    "else:\n",
    "    print('could not match up output string with preds.')\n",
    "b_preds_df.loc[:,'text':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-tim',\n",
       " 1: 'I-nat',\n",
       " 2: 'O',\n",
       " 3: 'I-eve',\n",
       " 4: 'I-per',\n",
       " 5: 'B-geo',\n",
       " 6: 'I-gpe',\n",
       " 7: 'B-nat',\n",
       " 8: 'I-org',\n",
       " 9: 'B-per',\n",
       " 10: 'B-gpe',\n",
       " 11: 'B-eve',\n",
       " 12: 'B-org',\n",
       " 13: 'I-tim',\n",
       " 14: 'B-art',\n",
       " 15: 'I-geo',\n",
       " 16: 'I-art'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
